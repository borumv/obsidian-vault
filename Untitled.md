Добрый день!
Пишу маленький учебный проект, для того чтобы разобрать в архитектуре Kafka и столкнулся с небольшими трудностями.
Задача следующая:
Есть большой csv файл с двумя столбцами (name, count). Нужно всего лишь сделать group by по name.

Задача масштабируемая и в голове нужно держать, что файл может быть большой + выполняется на разных нодах. Поэтому я написал сплиттер, где каждый сплит - это интервал с какой строки и по какую будет читать какой-либо Consumer из consumer-group (на разных нодах).

Каждую строку consumers отправляет в KafkaStream, где уже происходит groupBy по столбцу.

Данные обновляются, всё замечательно. Вот вопросы, которые у меня возникли
1. Но как мне сделать, чтобы в топики происходило обновление, только после полной обработки всех партиций. Т.е. чтобы я видел финальный groupBy? Понимаю, что может быть это не компетенции Kafka, но нужно сделать именно в ней.
2. Всегда присутствует ощущение того, что я выбрал неправильную архитектуру для решения задачи. Прикладываю маленькую схему, может вы поправите меня



